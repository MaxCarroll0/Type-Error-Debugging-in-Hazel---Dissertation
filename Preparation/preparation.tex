\chapter{Preparation}
\textit{In this chapter I present the core semantics and a larger overview of the Hazel language.}
\section{The Hazel Language}
\index{Hazel}
\textit{What is Hazel and who is developing it here.}

\subsection{Overview \& Vision}
\textit{Detail the vision of the Hazel project and main features of Hazel.}\par 
\textit{Finish with the state of the subset of Hazel for which the project was implemented.}

\subsection{\textbf{Core Hazel}: Formal Semantics}
For reference, the established semantics and type system for Hazel is presented. Derived from Omar et al.\ \cite{HazelLivePaper}. The paper itself goes into deeper depth into the intuition of the rules and the formal properties satisfied by the calculus.
\index{\textbf{Core Hazel}}
\footnote{
\textbf{Come up with and detail some good intuitions of what each type of value \& expression is and what the cast calculus and elaboration does.}}
\subsubsection{Syntax}

\par The syntax, in Fig. \ref{fig:syntax}, consists of \textit{types} $\tau$, \textit{external expressions} $e$, and \textit{internal expressions} $d$. Here, $?$ is the \textit{dynamic type}, $\hole[e]$ is a \textit{non-empty hole} containing $e$, and $\scast{\tau_1}{\tau_2}$,  $\scasterror{\tau_1}{\tau_2}$ are casts and cast errors from $\tau_1$ to $\tau_2$ respectively.
The \textit{external language} is a locally inferred \cite{LocalInference} surface syntax for the language, and is statically elaborated to (explicitly typed) \textit{internal expressions}, in a similar way to Harper and Stone's \cite{StandardMLTypeTheory} approach to defining Standard ML as elaboration to an explicitly typed internal langauge, \textit{XML} \cite{CoreXML}.
\begin{figure}[h]
\begin{align*}
\tau &::= b \mid \tau \to \tau \mid\  ?\\
e &::= c \mid x \mid \lambda x : \tau.e \mid \lambda x. e \mid e(e) \mid \hole^u \mid \hole[e]^u \mid e : \tau\\
d &::= c \mid x \mid \lambda x : \tau d \mid d(d) \mid \hole^u_\sigma \mid \hole[d]^u_\sigma \mid d\scast{\tau}{\tau} \mid d\scasterror{\tau}{\tau}
\end{align*}
\caption{Syntax: \textit{types} $\tau$, \textit{external expressions} $e$, \textit{internal expressions} $d$. With $x$ ranging over variables, $u$ over hole names, $\sigma$ over $x \to d$ \textit{internal language} substitutions/environments, $b$ over base types and $c$ over constants.}
\label{fig:syntax}
\end{figure}

\subsubsection{External Language: Type System}
The static semantics in Fig. \ref{fig:typing} of the \textit{external language} is a bidirectionally typed system in the style of Pierce and Turner \cite{LocalInference}, and Dunfield and Krishnaswami \cite{BidirectionalTypes}. There are two typing judgement modes: $\synthesis{e}{\tau}$ which synthesises a type $\tau$, algorithmically thought of as an output, and $\analysis{e}{\tau}$ which analyses against a type $\tau$ as an input.\par 
\begin{figure}[H]
\small
\fbox{$\synthesis{e}{\tau}$}\ \ \ $e$ synthesises type $\tau$ under context $\Gamma$
\tiny
\[\inference[\tiny SConst]{}{\synthesis{c}{b}} \quad
\inference[\tiny SVar]{x : \tau \in \Gamma}{\synthesis{x}{\tau}} \quad 
\inference[\tiny SFun]{\synthesis[\Gamma,x:\tau_1]{e}{\tau_2}}{\synthesis{\lambda x:\tau_1.e}{\tau_1 \to \tau_2}}\]
\[\inference[\tiny SApp]{\synthesis{e_1}{\tau_1} & \tau_1 \funmatch \tau_2 \to \tau \\ \analysis{e_2}{\tau_2}}{\synthesis{e_1(e_2)}{\tau}} \quad 
\inference[\tiny SEHole]{}{\synthesis{\hole^u}{?}} \quad \]
\[\inference[\tiny SNEHole]{\synthesis{e}{\tau}}{\synthesis{\hole[e]^u}{?}}\quad 
\inference[\tiny SAsc]{\analysis{e}{\tau}}{\synthesis{e : \tau}{\tau}}\]

\small
\fbox{$\analysis{e}{\tau}$}\ \ \ $e$ analyses against type $\tau$ under context $\Gamma$

\tiny
\[\inference[\tiny AFun]{\tau \funmatch \tau_1 \to \tau_2\\ \analysis[\Gamma, x:\tau_1]{e}{\tau_2}}{\analysis{\lambda x.e}{\tau}} \quad 
\inference[\tiny ASubsume]{\synthesis{e}{\tau}\\ \tau \sim \tau'}{\analysis{e}{\tau'}}\]

\caption{Bidirectional typing judgements for \textit{external expressions}}
\label{fig:typing}
\end{figure} 
These rules use a type consistency relation, $\sim$ in Fig. \ref{fig:consistency}, with types being consistent if they are equivalent up to the locations of the dynamic type. The type consistency relation is standard in gradual type systems \cite{GradualFunctional, GradualObjects}, and is similar to a subtyping relation but is \textit{not} transitive.

\begin{figure}[H]
\small
\fbox{$\tau_1 \sim \tau_2$}\ \ \ $\tau_1$ is consistent with $\tau_2$
\tiny
\[\inference[\tiny TCDyn1]{}{? \sim \tau} \quad \inference[\tiny TCDyn2]{}{\tau \sim ?} \quad \inference[\tiny TCRfl]{}{\tau \sim \tau} \quad \inference[\tiny TCFun]{\tau_1 \sim \tau_1' & \tau_2 \sim \tau_2'}{\tau_1 \to \tau_2 \sim \tau_1' \to \tau_2'}\]
\caption{Type consistency}
\label{fig:consistency}
\end{figure}
Finally, a (function) type matching relation, $\funmatch$ in Fig. \ref{fig:typematching}, matches the argument and return types from a function type, which for the dynamic type is $? \funmatch ? -> ?$. 
\begin{figure}[h]
\small
\fbox{$\tau \funmatch \tau_1 \to \tau_2$}\ \ \ $\tau$ has arrow type $\tau_1 \to \tau_2$
\tiny
\[\inference[\tiny MADyn]{}{? \funmatch ? \to ?} \quad 
\inference[\tiny MAFun]{}{\tau_1 \to \tau_2 \funmatch \tau_1 \to \tau_2}\]
\caption{Type Matching}
\label{fig:typematching}
\end{figure}


\subsubsection{Elaboration}
Elaboration to the \textit{internal language} is possible for well-typed \textit{external expressions} and consists of cast insertion, maintaining a hole context, and inserting initial identity hole environments. Each of these are used in the internal language type assignment $\typeassignment{e}{\tau}$ and the dynamic semantics. Fig. \ref{fig:elaboration} defines the elaboration judgements and Fig. \ref{fig:typeassignment} defines the internal language type assignment judgement.

\begin{figure}[h]
\small
\fbox{$\elaborationSynthesis{e}{\tau}{d}{\Delta}$}\ \ \ $e$ syntheses type $\tau$ and elaborates to $d$
\tiny 
\[\inference[\tiny ESConst]{}{\elaborationSynthesis{c}{b}{c}{\emptyset}} \quad 
\inference[\tiny ESVar]{x : \tau \in \Gamma}{\elaborationSynthesis{x}{\tau}{x}{\emptyset}}\]
\[\inference[\tiny ESFun]{\elaborationSynthesis[\Gamma,x:\tau_1]{e}{\tau_2}{d}{\Delta}}{\elaborationSynthesis{\lambda x:\tau_1.e}{\tau_1 \to \tau_2}{\lambda x:\tau_1. d}{\Delta}}\]
\[\inference[\tiny ESApp]{\synthesis{e_1}{\tau_1} & \tau_1 \funmatch \tau_2 \to \tau \\ \elaborationAnalysis{e_1}{\tau_2 \to \tau}{d_1}{\tau_1'}{\Delta_1} & \elaborationAnalysis{e_1}{\tau_2}{d_2}{\tau_2'}{\Delta_2}}{\elaborationSynthesis{e_1(e_2)}{\tau}{(d_1\scast{\tau_1}{\tau_2 \to \tau})(d_2\scast{\tau_2'}{\tau_2})}{\Delta_1 \cup \Delta_2}}\]
\[\inference[\tiny ESEHole]{}{\elaborationSynthesis{\hole^u}{?}{\hole^u_{\mathrm{id}(\Gamma)}}{u :: \hole[] [\Gamma]}}\]
\[\inference[\tiny ESNEHole]{\elaborationSynthesis{e}{\tau}{d}{\Delta}}{\elaborationSynthesis{\hole[e]^u}{?}{\hole[d]^u_{\mathrm{id}(\Gamma)}}{\Delta, u :: \hole[] [\Gamma]}}\]
\[\inference[\tiny ESAsc]{\elaborationAnalysis{e}{\tau}{d}{\tau'}{\Delta}}{\elaborationSynthesis{e:\tau}{\tau}{d\scast{\tau'}{\tau}}{\Delta}}\]
\small
\fbox{$\elaborationAnalysis{e}{\tau_1}{d}{\tau_2}{\Delta}$}\ \ \ $e$ analyses against type $\tau$ and elaborates to $d$ of consistent type $\tau_2$
\tiny 
\[\inference[\tiny EAFun]{\tau \funmatch \tau_1 \to \tau_2 \\ \elaborationAnalysis[\Gamma,x:\tau_1]{e}{\tau_2}{d}{\tau_2}{\Delta}}{\elaborationAnalysis{\lambda x. e}{\tau}{\lambda x:\tau_1. d : \tau_1 \to \tau_2'}{\Delta}}\]
\[\inference[\tiny EASubsume]{e \neq \hole^u & e \neq \hole[e']^u \\ \elaborationSynthesis{e}{\tau'}{d}{\Delta} & \tau \sim \tau'}{\elaborationAnalysis{e}{\tau}{d}{\tau'}{\Delta}}\]
\[\inference[\tiny EAEHole]{}{\elaborationAnalysis{\hole^u}{\tau}{\hole^u_{\mathrm{id}(\Gamma)}}{\tau}{u::\tau[\Gamma]}}\]
\[\inference[\tiny EANEHole]{\elaborationSynthesis{e}{\tau'}{d}{\Delta}}{\elaborationAnalysis{\hole[e]^u}{\tau}{\hole[d]^u_{\mathrm{id}(\Gamma)}}{\tau}{u::\tau[\Gamma]}}\]

\caption{Elaboration judgements} 
\label{fig:elaboration}
\end{figure}

\begin{figure}
\small
\fbox{$\typeassignment{d}{\tau}$}\ \ \ $d$ is assigned type $\tau$
\tiny
\[\inference[\tiny TACons]{}{\typeassignment{c}{b}}\quad
\inference[\tiny TAVar]{x : \tau \in \Gamma}{\typeassignment{x}{\tau}}\quad
\inference[\tiny TAFun]{\typeassignment[\Delta;\Gamma,x:\tau_1]{d}{\tau_2}}{\typeassignment{\lambda x:\tau_1. d}{\tau_1 \to \tau_2}}\]
\[\inference[\tiny TAApp]{\typeassignment{d_1}{\tau_2 \to \tau} \\ \typeassignment{d_2}{\tau_2}}{\typeassignment{d_1(d_2)}{\tau}} \quad 
\inference[\tiny TAEHole]{u :: \tau[\Gamma'] \in \Delta \\ \typeassignment{\sigma}{\Gamma'}}{\typeassignment{\hole^u_\sigma}{\tau}}\]
\[
\inference[\tiny TANEHole]{\typeassignment{d}{\tau'} \\ u :: \tau[\Gamma' \in \Delta & \typeassignment{\sigma}{\Gamma'}]}{\typeassignment{\hole[d]^u_\sigma}{\tau}}\quad 
\inference[\tiny TACast]{\typeassignment{d}{\tau_1} & \tau_1 \sim \tau_2}{\typeassignment{d\scast{\tau_1}{\tau_2}}{\tau_2}}\]
\[\inference[\tiny TACastError]{\typeassignment{d}{\tau_1} & \tau_1\text{ ground} & \tau_2\text{ ground} & \tau_1 \neq \tau_2}{\typeassignment{d\scasterror{\tau_1}{\tau_2}}{\tau_2}}\]
\caption{Type assignment judgement for \textit{internal expressions}}
\label{fig:typeassignment}
\end{figure}
Notice that cast errors -- casts between distinct ground types -- are well typed, where ground types are base types or one-level unrollings of the dynamic type (each being the \textit{least specific} type for each compound type).
\begin{figure}
\tiny
\[id(x_1:\tau_1, \dots, x_n:\tau_n) := [x_1/x_1, \dots, x_n/x_n]\]
\[\typeassignment{\sigma}{\Gamma'} \text{ iff } \mathrm{dom}(\sigma) = \mathrm{dom}(\Gamma')\text{ and for every } x : \tau \in \Gamma' \text{ then:
} \typeassignment{\sigma(x)}{\tau}\]
\caption{Identity substitution and substitution typing}
\label{fig:substitutiontyping}
\end{figure}

\begin{figure}
\tiny
\fbox{$\tau$ ground}\ \ \ $\tau$ is a ground type
\[\inference[\tiny GBase]{}{b\text{ ground}}\quad \inference[\tiny GDynFun]{}{? \to ?\text{ ground}}\]
\caption{Ground types}
\label{fig:groundtypes}
\end{figure}
This elaboration is proven to produce unique internal expressions and hole contexts, and to preserve well-typedness.

\subsubsection{Internal Language: Dynamic Semantics}
In order to support the ability to evaluate expressions around holes and cast errors, Hazel defines multiple syntax-directed classes of final forms in Fig. \ref{fig:finalforms}. \textit{Final forms} are irreducible expressions.
\begin{itemize}
\item Values -- Constants or functions.
\item Boxed values -- Values or boxed values in one of the two cast forms. These must be unboxed (downcast) before reducing.
\item Indeterminate forms -- Irreducible terms containing holes or are casts errors. Substitution of holes may make these reducible.
\item Final -- All final forms.
\end{itemize}

\begin{figure}[h]
\small
\fbox{$\final$}\ \ \ $d$ is final
\tiny
\[\inference[\tiny FBoxedVal]{\boxedval}{\final}\quad
\inference[\tiny FIndex]{\indet}{\final}\]
\small
\fbox{$\val$}\ \ \ $d$ is a value
\tiny
\[\inference[\tiny VConst]{}{\val[c]}\quad
\inference[\tiny VFun]{}{\val[\lambda x:\tau. d]}\]
\small
\fbox{$\boxedval$}\ \ \ $d$ is a boxed value
\tiny
\[\inference[\tiny BVVal]{\val}{\boxedval}\quad
\inference[\tiny BVFunCast]{\tau \to \tau_2 \neq \tau_3 \to \tau_4 & \boxedval}{\boxedval[d\scast{\tau_1 \to \tau_2}{\tau_3 \to \tau_4}]}\]
\[\inference[\tiny BVDynCast]{\boxedval & \ground}{\boxedval[d\scast{\tau}{?}]}\]
\small
\fbox{$\indet$}\ \ \ $d$ is indeterminate
\tiny
\[\inference[\tiny IEHole]{}{\indet[\hole^u_\sigma]}\quad
\inference[\tiny INEHole]{\final}{\indet[{\hole[d]^u_\sigma}]}\quad
\inference[\tiny IAp]{d_1 \neq d_1'\scast{\tau_1 \to \tau_2}{\tau_3 \to \tau_4} \\ \indet[d_1] & \final[d_2]}{\indet[d_1(d_2)]}\]
\[\inference[\tiny ICastGD]{\indet & \ground}{\indet[d\scast{\tau}{?}]}\quad
\inference[\tiny ICastDG]{d \neq d'\scast{\tau'}{?} & \indet & \ground}{\indet[d\scast{?}{\tau}]}\]
\[\inference[\tiny ICastFun]{\tau_1 \to \tau_2 \neq \tau_3 \to \tau_4 & \indet}{\indet[d\scast{\tau_1 \to \tau_2}{\tau_3 \to \tau_4}]}\quad
\inference[\tiny ICastError]{\final & \ground[\tau_1] \\ \ground[\tau_2] & \tau_1 \neq \tau_2}{\indet[d\scasterror{\tau_1}{\tau_2}]}\]

\caption{Final forms}
\label{fig:finalforms}
\end{figure}


The small-step contextual dynamics \cite{PracticalFoundations} is defined on the internal expressions. The general idea is to consider two classes of casts: injections -- casts from a ground type to the dynamic types, and projections -- casts from the dynamic type to a ground type. These two classes of casts can be eliminated upon meeting if the ground types are equal or to a cast error if not. Function casts are dealt with by separating into two casts on the argument and return value. Finally, compound types can be cast to their least specific ground type specified by the ground matching relation in Fig. \ref{fig:groundmatch}.

\begin{figure}
\small
\fbox{$\tau \groundmatch \tau'$}\ \ \ $\tau$ matches ground type $\tau'$
\tiny
\[\inference[\tiny]{\tau_1 \to \tau_2 \neq ? \to ?}{\tau_1 \to \tau_2 \groundmatch ? \to ?}\]
\caption{Ground type matching}
\label{fig:groundmatch}
\end{figure}

The instruction transitions, Fig. \ref{fig:instructions}, and evaluation context, Fig. \ref{fig:dynamics}, specify a non-deterministic evaluation order, which is a more suitable choice for supporting dynamic hole instantiation, as will be used by the search procedure.\footnote{\textbf{Define Substitution in appendices?}}\par 
Casts are associative, so bracketing is omitted.
\begin{figure}
\small
\fbox{$d \longrightarrow d'$}\ \ \ $d$ takes and instruction transition to $d'$
\tiny
\[\inference[\tiny ITFun]{}{(\lambda x:\tau. d_1)(d_2) \longrightarrow [d_2/x]d_1}\quad
\inference[\tiny ITCastId]{}{d\scast{\tau}{\tau} \longrightarrow d}\]
\[\inference[\tiny ITAppCast]{\tau_1 \to \tau_2 \neq \tau_1' \to \tau_2'}{d_1\scast{\tau_1 \to \tau_2}{\tau_1' \to \tau_2'}(d) \longrightarrow (d_1(d_2\scast{\tau_1'}{\tau_1}))\scast{\tau_2}{\tau_2'}}\]
\[\inference[\tiny ITCast]{\ground}{d\scastcast{\tau}{?}{\tau} \longrightarrow d} \quad
\inference[\tiny ITCastError]{\tau_1 \neq \tau_2 \\ \ground[\tau_1] & \ground[\tau_2]}{d\scastcast{\tau_1}{?}{\tau_2}\longrightarrow d\scasterror{\tau_1}{?}{\tau_2}}\]
\[\inference[\tiny ITGround]{\tau \groundmatch \tau'}{d\scast{\tau}{?} \longrightarrow d\scastcast{\tau}{\tau'}{?}}\quad
\inference[\tiny ITExpand]{\tau \groundmatch \tau'}{d\scast{?}{\tau} \longrightarrow d\scastcast{?}{\tau'}{\tau}}\]
\caption{Instruction transitions}
\label{fig:instructions}
\end{figure}

\begin{figure}
Context syntax:
\[E ::= \circ \mid E(d) \mid d(E) \mid \hole[E]^u_\sigma \mid E\scast{\tau}{\tau} \mid E\scasterror{\tau}{\tau}\]
\small
\fbox{$d = E[d]$}\ \ \ $d$ is the context $E$ filled with $d'$ in place of $\circ$
\tiny
\[\inference[\tiny ECOuter]{}{d = \circ[d]} \quad
\inference[\tiny ECApp1]{d_1 = E[d_1']}{d_1(d_2) = E(d_2)[d_1]}\quad
\inference[\tiny ECApp2]{d_2 = E[d_2]}{d_1(d_2) = d_1(E)[d_2']}\]
\[\inference[\tiny ECNEHole]{d=E[d']}{\hole[d]^u_\sigma = \hole[E]^u_\sigma [d']}\quad
\inference[\tiny ECCast]{d=E[d']}{d\scast{\tau_1}{\tau_2} = E\scast{\tau_1}{\tau_2}[d']}\]
\[\inference[\tiny ECCastError]{d=E[d']}{d\scasterror{\tau_1}{\tau_2} = E\scasterror{\tau_1}{\tau_2}[d']}\]
\small
\fbox{$d \mapsto d'$}\ \ \ $d$ steps to $d'$
\tiny
\[\inference[\tiny Step]{d_1=E[d_2] & d_2 \longrightarrow d_2' & d_1' = E[d_2']}{d_1 \mapsto d_1'}\]
\caption{Contextual dynamics of the internal language}
\label{fig:dynamics}
\end{figure}
%\subsection{System F}  % Only include this section if actually used, other potential sections could be on pattern matching etc.
%\textit{System F and how it is adapted to Hazel}

\subsection{Hazel Codebase}

\section{The Project}
\subsection{Cast Slicing}
Cast slicing is, to my knowledge, a new concept and is a method in which selected casts can be linked back to source code by creating a slice of all code contributing to the cast.\par 
Slicing methods have been researched extensively since Wadler first proposed static program slicing \cite{ProgSlice}, and later others proposed dynamic program slicing \cite{DynProgSlice} and error slicing \cite{ErrSlice}. Cast slicing combines ideas from both dynamic slicing, tracking of casts during evaluation, and error slicing, tracking casts during static elaboration. But is relatively less expressive in terms of slicing criterion, only considering casts, and no other expressions.

\subsection{Search Procedure}
Search procedure for witnesses of type errors has been considered by Seidel et al. \cite{SearchProc} for OCaml. Their approach creates a non-deterministic semantics for ill-typed OCaml with a hole in place of a function argument being dynamically type inferred and instantiated in a most general manner until evaluation gets stuck. The hole instantiation at this point is the error witness.\par 
Adapting this search procedure to Hazel, which natively supports evaluation of ill-typed expressions, and hole substitution analogously to contextual modal type theory \cite{CMTT}\footnote{Explore}.\par 
Further, the use of dynamic types, casts, and the more general notion of holes will allow better handling of non-parametric function types -- stated as a problem in Seidel et al's. paper. Hence, very different semantics will need to be devised, but the general principle of dynamic inference and hole instantiation will remain the same.\footnote{Talk more deeply about CMTT and how hole substitution is efficient in Hazel.}

\section{Starting Point}
\subsubsection{Concepts}
The foundations of most concepts in understanding Hazel from Part IB Semantics of Programming (and Part II Types later). The concept of gradual typing briefly appeared in Part IB Concepts of Programming Languages, but was not formalised. Dynamic typing, gradual typing, holes, and contextual modal type theory were not covered in Part IB, so were partially researched leading up to the project, then researched further in greater depth during the early stages. Similarly, Part IB Artificial Integlligence provided some context to search procedures, however nothing was directly relevant. Primarily, the OCaml search procedure for ill-typed witnesses Seidel et al. \cite{SearchProc} and the Hazel core language \cite{HazelLivePaper} were researched over the preceding summer.

\subsubsection{Tools and Source Code}
My experience in OCaml was mostly from the Part IA Foundations of Computer Science course and small-scale personal projects. The Hazel source code had not been inspected in detail until after starting the project.

\section{Requirement Analysis}

\section{Software Engineering Methodology}

\section{Legality}
