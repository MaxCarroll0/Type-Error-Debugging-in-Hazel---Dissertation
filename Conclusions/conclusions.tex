\chapter{Conclusions}\label{chap:Conclusions}
This project aimed to enhance type error debugging in Hazel by implementing two novel features: \textit{type slicing} and \textit{cast slicing}. These features were successfully formalised and implemented, with further variations explored and incorporated.

Type slicing provided comprehensive explanations for expressions' types and errors. It proved more expressive than initially planned, applying to all expressions, not just errors, hence being useful in more situations. Cast slicing effectively linked dynamic (cast) errors with the static code context that caused them. Further, they provided more concise explanations for errors than type slices.

Additionally, a search procedure successfully found dynamic witnesses for static type error in the majority of cases. Together, these features cohesively provide a richer, more intuitive type debugging system and a expanded framework to learn how the type system works, offering both abstract and concrete perspectives on type errors.

\section{Further Directions}
This section presents some \textit{extensions} to improve the features as justified by the evaluation (\cref{sec:CriticalAnalysis} \& \ref{sec:HolisticEvaluation}) alongside other interesting {applications}. 

\subsection{UI Improvements, User Studies}
The current UI can be improved as suggested in \Cref{sec:UIImprovements}. Once these are implemented, a user study could assess the real world effectiveness of type slicing and cast slicing in improving understanding of the type system, and locating errors.

\subsection{Cast Slicing}
Cast slicing only propagates type slice information throughout evaluation. As demonstrated, this is useful for debugging. But, it provides no slicing on execution properties of the program. Extended slicing methods could, for example, provide a minimal program which evaluates to the \textit{same} cast around the \textit{same} value. This could build on traditional \textit{dynamic slicing} methods \cite{DynProgSlice, FunctionalProgExplain}, and find use also in debugging \textit{semantic} errors.

\subsection{Property Testing}
Indeterminate evaluation provides a way to generate inputs to function. So, it could be used for property testing, generating inputs to functions and testing expressions. A framework similar to SmallCheck \cite{SmallCheck} or QuickCheck \cite{QuickCheck} could be implemented. Being part of the evaluator, intermediate expressions and execution properties could also be tested.

\subsection{Non-determinism, Connections to Logic Programming}
\label{sec:LogicProgramming}
Non-deterministic evaluation could be harnessed to implement non-deterministic constructs (e.g. a choice operator) for Hazel.

Treating holes as unknowns and instantiating lazily is reminiscent of \textit{free logic variables} in functional logic programming languages \cite{FunctionalLogicProgramming}, e.g. in \textit{Curry} \cite{CurryLang}. Adding unification \cite{UnificationSurvey} would allow full logic programming in Hazel. A needed-narrowing evaluation strategy \cite{NeededNarrowing} would be an significantly more efficient than the current lazy non-deterministic instantiation. Equally, unification and needed narrowing could be applied to generating type witnesses.

\subsection{Symbolic Execution}
The search procedure cannot always find witnesses, usually when branches containing the error are missed during the search. This problem has been extensively researched for automated test generation and program verification, often using symbolic execution \cite{SymbolicExecutionSurvey}. Constraints along execution paths can be modelled via satisfiability modulo theories (SMTs) \cite{SMTs}, for which there exist many efficient solvers \cite{SMTSolver}.

Indeterminate evaluation can be consider a form of simple {symbolic execution}, only considering constraints enforced by casts. \Cref{sec:ExtendedPatternMatching} considered directing instantiation using patterns within match statements. 

\subsubsection{Polymorphism}
The set of possible types is infinite. Generating witnesses for polymorphic values is then a much expanded state-space. Symbolic theories and solvers for polymorphic operations, would help in this situation.

\subsection{Let Polymorphism \& Global Inference}
Types in globally inferred languages are often more subtle, as there are fewer annotations asserting the programmers intent. Extension to type slicing would be useful in understanding why expressions have their globally inferred types. Further, Seidel et al. provides evidence that the witness search procedure is particularly useful in such languages, aiding in error localisation.

\subsubsection{In Hazel}
Global inference is difficult or impossible to combine with complex type systems. Global inference for high rank polymorphism, like Hazel's System-F style polymorphism, is undecidable \cite{SystemFUndecidable}). 

However, a form of let-polymorphism via principal type schemes \cite{PrincipleTypeSchemes} is possible. Intersection this with gradual typing has been explored by Garcia and Cimini \cite{GradualTI} and Miyazaki et al. \cite{DTI}, the latter of which would integrate most smoothly with Hazel and indeterminate evaluation. 

Hazel currently has a branch exploring global inference \texttt{(thi)}, although without polymorphism as of yet.

\subsubsection{Constraint Slicing}
The search procedure and cast slicing are relatively easily extended to a let-polymorphic Hazel in the style of Miyazaki et al. However, type slicing now has to consider non-local constraints alongside code which sourced them, differing significantly from bidirectional type slicing. Somewhat similar ideas, but limited only to errors, have been explored in \textit{constraint-based type error slicing} by Haack and Wells \cite{HaackErrSlice}.

\section{Reflections}
TODO