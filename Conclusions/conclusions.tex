\chapter{Conclusions}\label{chap:Conclusions}
All core goals and extensions set out in \cref{sec:RequirementAnalysis} were achieved except for the low priority extensions, of which extended pattern instantiation was partially implemented. All must/should/could have features of Hazel were supported except for only partial support for labelled tuples and type substitution.

Type slicing proved more expressive than initially planned, applying to \textit{all} expressions, \textit{not just errors}. Therefore, it can also be used to learn and build understanding on how Hazel's type system works, not just for debugging errors. 

An indeterminate evaluation framework (\cref{sec:IndetEval}) was built, greatly generalising the original search procedure \cite{SearchProc} to allow multiple search orderings, and different classes of results, e.g. concrete values, or derived results like expression sizes.
\section{Further Directions}
\subsection{UI Improvements, User Studies}
During the holistic evaluation, various usability and UI improvements were considered and added as low-priority extensions (\cref{sec:UIImprovements}). Once implemented, a user study could assess the real world effectiveness of type slicing and cast slicing in improving understanding of the type system, and locating errors.

\subsection{Cast Slicing}
Cast slicing propagates type slice information throughout evaluation. But, it provide no slicing on \textit{execution properties} of the program. Extended slicing methods could, for example, provide a minimal program which evaluates to the \textit{same} cast around the \textit{same} value. This could build on traditional \textit{dynamic slicing} methods \cite{DynProgSlice, FunctionalProgExplain}, and find use also in debugging \textit{semantic} errors.

\subsection{Property Testing}
A framework similar to SmallCheck \cite{SmallCheck} or QuickCheck \cite{QuickCheck} could be implemented via indeterminate evaluation. Additionally, execution properties could also be tested.

\subsection{Non-determinism, Connections to Logic Programming}
\label{sec:LogicProgramming}
Non-deterministic evaluation could be harnessed to implement non-deterministic constructs (e.g. a choice operator) for Hazel. Treating holes as unknowns and instantiating lazily is reminiscent of \textit{free logic variables} in functional logic programming languages \cite{FunctionalLogicProgramming}, e.g. in \textit{Curry} \cite{CurryLang}. Adding unification \cite{UnificationSurvey} would allow full logic programming in Hazel. A needed-narrowing evaluation strategy \cite{NeededNarrowing} would be an significantly more efficient than the current lazy non-deterministic instantiation.

\subsection{Symbolic Execution}
Use of symbolic Execution \cite{SymbolicExecutionSurvey} would improve the proportion of witnesses found by the search procedure by improving code coverage (\cref{sec:EvalHoleInstantiation}). Indeterminate evaluation can be considered a form of simple {symbolic execution}, only considering constraints enforced by casts. \Cref{sec:ExtendedPatternMatching} considered directing instantiation using patterns within match statements. 

\subsection{Let Polymorphism \& Global Inference}
Types in globally inferred languages are often more subtle, as there are fewer annotations asserting the programmers intent. This project would be particularly useful in these situations.

\paragraph{In Hazel}
Global inference is difficult or impossible to combine with complex type systems. Global inference for high rank polymorphism, like Hazel's System-F style polymorphism, is undecidable \cite{SystemFUndecidable}.  However, a form of let-polymorphism via principal type schemes \cite{PrincipleTypeSchemes} is possible. Intersecting this with gradual typing has been explored by Garcia and Cimini \cite{GradualTI} and Miyazaki et al. \cite{DTI}, the latter of which would integrate most smoothly with Hazel and indeterminate evaluation.

\paragraph{Constraint Slicing}
The search procedure and cast slicing are relatively easily extended to a let-polymorphic Hazel in the style of Miyazaki et al. However, type slicing now has to consider non-local constraints alongside code which sourced them, differing significantly from bidirectional type slicing. Somewhat similar ideas, but limited only to errors, have been explored in \textit{constraint-based type error slicing} by Haack and Wells \cite{HaackErrSlice}.

\section{Lessons Learnt}
This project required extensive theory and mathematical thought, requiring in extensive reading of the surrounding research. I have, therefore, learnt how to effectively find \textit{relevant} research and quickly extract and understand their key contributions.

Further, it worked on the rapidly moving open-source codebase Hazel. As such, I have learnt how a large software project works, learning how to use effectively use version control and continuous integration tools. Additionally, communicating with other developers has offered insights into how collaborative development of software works.

The result was an extensive multi-faceted project, requiring great effort. On reflection, it might have been better to focus on either type slicing \textit{or} the search procedure, allowing time to turn one of these into a truly \textit{usable} debugging aid. In retrospect, it would have been more time-efficient and rigorous to fully automate slicing tests, creating a framework that abstracts away the randomised term IDs within slices.